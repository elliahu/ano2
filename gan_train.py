import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import ImageFolder
from gan import Generator, Discriminator
import os

# Paths to training data
TRAIN_PATH = "train_images"
MODEL_PATH = "models/gan_model.pth"

# Initialize the models
generator = Generator()
discriminator = Discriminator()

# Define the loss function and optimizers
criterion = nn.BCELoss()
optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Function to save the model
def save_model(generator, discriminator, optimizer_g, optimizer_d, epoch, filename=MODEL_PATH):
    torch.save({
        'epoch': epoch,
        'generator_state_dict': generator.state_dict(),
        'discriminator_state_dict': discriminator.state_dict(),
        'optimizer_g_state_dict': optimizer_g.state_dict(),
        'optimizer_d_state_dict': optimizer_d.state_dict(),
    }, filename)
    print(f"Model saved to {filename}")



# Define the transformation for training images
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

# Load the dataset and create the DataLoader
dataset = ImageFolder(root=TRAIN_PATH, transform=transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# Training loop
def train_gan(generator, discriminator, dataloader, criterion, optimizer_g, optimizer_d, num_epochs=10):
    for epoch in range(num_epochs):
        generator.train()
        discriminator.train()
        running_loss_g = 0.0
        running_loss_d = 0.0

        for images, _ in dataloader:
            batch_size = images.size(0)
            real_labels = torch.ones(batch_size, 1)
            fake_labels = torch.zeros(batch_size, 1)

            # Move data to device (GPU or CPU)
            images = images.to(device)
            real_labels = real_labels.to(device)
            fake_labels = fake_labels.to(device)

            # -----------------
            # Train Discriminator
            # -----------------
            optimizer_d.zero_grad()

            # Train with real images
            outputs = discriminator(images)
            loss_d_real = criterion(outputs, real_labels)
            loss_d_real.backward()

            # Train with fake images (generated by the generator)
            z = torch.randn(batch_size, 100).to(device)
            fake_images = generator(z)
            outputs = discriminator(fake_images.detach())
            loss_d_fake = criterion(outputs, fake_labels)
            loss_d_fake.backward()

            optimizer_d.step()

            # -----------------
            # Train Generator
            # -----------------
            optimizer_g.zero_grad()

            # We want to fool the discriminator, so we use real labels for the fake images
            outputs = discriminator(fake_images)
            loss_g = criterion(outputs, real_labels)
            loss_g.backward()

            optimizer_g.step()

            running_loss_g += loss_g.item() * batch_size
            running_loss_d += (loss_d_real.item() + loss_d_fake.item()) * batch_size

        # Calculate average loss for the epoch
        epoch_loss_g = running_loss_g / len(dataloader.dataset)
        epoch_loss_d = running_loss_d / len(dataloader.dataset)

        print(f"Epoch {epoch+1}/{num_epochs}, Loss G: {epoch_loss_g:.4f}, Loss D: {epoch_loss_d:.4f}")

        # Save model every few epochs
        if (epoch + 1) % 10 == 0:
            save_model(generator, discriminator, optimizer_g, optimizer_d, epoch)

# Check if GPU is available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Move models to the appropriate device
generator = generator.to(device)
discriminator = discriminator.to(device)

# Create directory for saving model if it doesn't exist
os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)

# Start training
train_gan(generator, discriminator, dataloader, criterion, optimizer_g, optimizer_d, num_epochs=100)
